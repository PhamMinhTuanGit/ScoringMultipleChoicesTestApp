{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from utilities import extract_bubbles, append_to_file\n",
    "from image_processing import getNails\n",
    "from grid_info import getGridmatrix, getExtractsections\n",
    "from fixed_coordinates import fixed_circle\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from result_processsing import getSubmitResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"IMG_1581_iter_0.jpg\"\n",
    "coord_saver = \"test.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers of black squares (YOLOv8 format): [(0.9157427937915743, 0.928911456680419), (0.7707317073170732, 0.9247857822913361), (0.6283813747228382, 0.9216121866074262), (0.4878048780487805, 0.9190733100602984), (0.34767184035476717, 0.9174865122183434), (0.20709534368070953, 0.9165344335131704), (0.06607538802660753, 0.9152649952396065), (0.9152993348115299, 0.6708981275785465), (0.7725055432372505, 0.6686766105998095), (0.7015521064301552, 0.6677245318946367), (0.6310421286031042, 0.6667724531894637), (0.4909090909090909, 0.6651856553475087), (0.3507760532150776, 0.6642335766423357), (0.2811529933481153, 0.6635988575055538), (0.2106430155210643, 0.6632814979371628), (0.06873614190687362, 0.6620120596635989), (0.9170731707317074, 0.5445890193589337), (0.7033259423503326, 0.5420501428118057), (0.49223946784922396, 0.5401459854014599), (0.282039911308204, 0.5385591875595049), (0.06962305986696231, 0.536337670580768), (0.9206208425720621, 0.34306569343065696), (0.8310421286031042, 0.3268803554427166), (0.6864745011086475, 0.3252935576007617), (0.493569844789357, 0.34052681688352904), (0.282039911308204, 0.3386226594731831), (0.07184035476718403, 0.33767058076801015), (0.8337028824833703, 0.13075214217708664), (0.6886917960088692, 0.13011742304030466), (0.9254988913525499, 0.07489685814027293), (0.07272727272727272, 0.07267534116153603)]\n",
      "Centers of black squares (YOLOv8 format): [(0.9175166297117516, 0.9282767375436369), (0.7725055432372505, 0.924468422722945), (0.6297117516629712, 0.9212948270390352), (0.48957871396895786, 0.9190733100602984), (0.34944567627494455, 0.9178038717867344), (0.20842572062084258, 0.9168517930815614), (0.06784922394678493, 0.9158997143763884), (0.9157427937915743, 0.6702634084417646), (0.7733924611973393, 0.6683592510314186), (0.7019955654101996, 0.6674071723262457), (0.6314855875831485, 0.6664550936210727), (0.49135254988913524, 0.6651856553475087), (0.35121951219512193, 0.6645509362107268), (0.28159645232815966, 0.6639162170739448), (0.21108647450110865, 0.6635988575055538), (0.06917960088691796, 0.6626467788003808), (0.9175166297117516, 0.5436369406537607), (0.7033259423503326, 0.5417327832434148), (0.49223946784922396, 0.5401459854014599), (0.282039911308204, 0.5388765471278959), (0.07006651884700665, 0.53697238971755), (0.9201773835920177, 0.34211361472548396), (0.8301552106430156, 0.3262456363059346), (0.6855875831485587, 0.32497619803237066), (0.4931263858093126, 0.34052681688352904), (0.28159645232815966, 0.3389400190415741), (0.07139689578713969, 0.33830529990479213), (0.8323725055432373, 0.13011742304030466), (0.6873614190687362, 0.12980006347191367), (0.9241685144124169, 0.07394477943509997), (0.07095343680709534, 0.07362741986670898)]\n",
      "Dữ liệu đã được ghi vào file test.txt.\n"
     ]
    }
   ],
   "source": [
    "fixed_circle(img_path, coord_saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from train_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "inputs = []\n",
    "targets = []\n",
    "image = cv2.imread(img_path)\n",
    "labels, coords = read_file_to_tensors(coord_saver)\n",
    "for i, coord in enumerate(coords):\n",
    "    x1, y1, x2, y2 = find_yolov8_square(image, coord)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "cv2.imwrite(\"/Users/phamminhtuan/Desktop/AIChallenge/avg_coords.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        # Depthwise convolution\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "        # Pointwise convolution\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu6(self.bn1(self.depthwise(x)))\n",
    "        x = torch.nn.functional.relu6(self.bn2(self.pointwise(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(MobileNet, self).__init__()\n",
    "\n",
    "        def conv_bn(in_channels, out_channels, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU6(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_bn(3, 32, 2),  # input size: 32x32x3, output size: 16x16x32\n",
    "            DepthwiseSeparableConv(32, 64, 1),  # output size: 16x16x64\n",
    "            DepthwiseSeparableConv(64, 128, 2), # output size: 8x8x128\n",
    "            DepthwiseSeparableConv(128, 128, 1),# output size: 8x8x128\n",
    "            DepthwiseSeparableConv(128, 256, 2),# output size: 4x4x256\n",
    "            DepthwiseSeparableConv(256, 256, 1),# output size: 4x4x256\n",
    "            DepthwiseSeparableConv(256, 512, 2),# output size: 2x2x512\n",
    "            DepthwiseSeparableConv(512, 512, 1),# 5x repeated, output size: 2x2x512\n",
    "            DepthwiseSeparableConv(512, 512, 1),\n",
    "            DepthwiseSeparableConv(512, 512, 1),\n",
    "            DepthwiseSeparableConv(512, 512, 1),\n",
    "            DepthwiseSeparableConv(512, 512, 1),\n",
    "            DepthwiseSeparableConv(512, 1024, 2),# output size: 1x1x1024\n",
    "            DepthwiseSeparableConv(1024, 1024, 1),# output size: 1x1x1024\n",
    "            nn.AdaptiveAvgPool2d(1), # output size: 1x1x1024\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = MobileNet(num_classes=2)  # Chuyển mô hình sang GPU nếu có\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CroatianFishClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super(CroatianFishClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.train_accuracies = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "\n",
    "    def accuracy(self, logits, labels):\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total = labels.size(0)\n",
    "        out = correct / total\n",
    "        return out\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return {'test_loss': loss, 'test_acc': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best checkpoint from: /Users/phamminhtuan/Desktop/AIChallenge/lightning_logs/version_8/checkpoints/best-checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra checkpoint tốt nhất\n",
    "best_checkpoint_path = \"/Users/phamminhtuan/Desktop/AIChallenge/lightning_logs/version_8/checkpoints/best-checkpoint.ckpt\"\n",
    "if best_checkpoint_path:\n",
    "    print(f\"Loading best checkpoint from: {best_checkpoint_path}\")\n",
    "    \n",
    "    # Load mô hình từ checkpoint (gọi trực tiếp trên class)\n",
    "    model = CroatianFishClassifier.load_from_checkpoint(best_checkpoint_path)\n",
    "    \n",
    "    # Chuyển mô hình sang chế độ đánh giá\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "else:\n",
    "    print(\"No best checkpoint found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151 2255\n"
     ]
    }
   ],
   "source": [
    "h, w = image.shape[:2]\n",
    "print(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sort_to_convex_quadrilateral(dots):\n",
    "    \"\"\"\n",
    "    Sorts a tuple of 4 dots into the order of a convex quadrilateral.\n",
    "\n",
    "    :param dots: A tuple or list of 4 tuples, each representing (x, y) coordinates of a point\n",
    "    :return: A list of 4 tuples sorted into a convex quadrilateral order\n",
    "    \"\"\"\n",
    "    if len(dots) != 4:\n",
    "        raise ValueError(\"Input must contain exactly 4 dots.\")\n",
    "\n",
    "    # Calculate the centroid of the points\n",
    "    centroid_x = sum(dot[0] for dot in dots) / 4\n",
    "    centroid_y = sum(dot[1] for dot in dots) / 4\n",
    "\n",
    "    # Function to calculate the polar angle of a point relative to the centroid\n",
    "    def polar_angle(dot):\n",
    "        x, y = dot\n",
    "        return math.atan2(y - centroid_y, x - centroid_x)\n",
    "\n",
    "    # Sort the dots by their polar angle relative to the centroid\n",
    "    sorted_dots = sorted(dots, key=polar_angle)\n",
    "    return sorted_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.cluster import DBSCAN\n",
    "def getBubblesInClass(input_image_path, input_data, section_index, axis = 0, eps = 0.002):\n",
    "        centers = image_processing.getNails(input_image_path)\n",
    "        gridmatrix = grid_info.getGridmatrix(centers)\n",
    "        gridsection = grid_info.getExtractsections(gridmatrix)\n",
    "        dots = extract_bubbles(input_data)\n",
    "        corners = gridsection[section_index[0]][section_index[1]]\n",
    "        corners = sort_to_convex_quadrilateral(corners)\n",
    "        if len(corners) != 4:\n",
    "                raise ValueError(\"Exactly 4 corners are required to define a quadrilateral.\")\n",
    "\n",
    "                # Create a Polygon object using the corners\n",
    "        polygon = Polygon(corners)\n",
    "\n",
    "                # Filter dots that are inside the polygon (only checking x and y values)\n",
    "        inside_dots = [dot for dot in dots if polygon.contains(Point(dot[1], dot[2]))]\n",
    "        dots = inside_dots\n",
    "        values = np.array([dot[axis + 1] for dot in dots]).reshape(-1, 1)\n",
    "        if axis == 0:\n",
    "            eps = 0.005\n",
    "\n",
    "        # Apply DBSCAN clustering\n",
    "        clustering = DBSCAN(eps=eps, min_samples=1).fit(values)\n",
    "\n",
    "        # Group dots by their cluster labels\n",
    "        batches = {}\n",
    "        for label, dot in zip(clustering.labels_, dots):\n",
    "            if label not in batches:\n",
    "                batches[label] = []\n",
    "            batches[label].append(dot)\n",
    "\n",
    "        # Convert batches to a list of clusters\n",
    "        clustered_batches = [\n",
    "            sorted(batches[label], key=lambda dot: dot[1 if axis == 1 else 2])\n",
    "            for label in sorted(batches.keys())\n",
    "        ]\n",
    "        return sorted(clustered_batches, key=lambda batch: batch[0][axis + 1])\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sections = [\n",
    "            {\"name\": \"SBD\", \"section_index\": (0, 0), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"SBD\", \"gap_string\": 0},\n",
    "            {\"name\": \"MDT\", \"section_index\": (0, 1), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"MDT\", \"gap_string\": 0},\n",
    "            {\"name\": \"phan1_1\", \"section_index\": (1, 0), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"1.\", \"gap_string\": 0},\n",
    "            {\"name\": \"phan1_2\", \"section_index\": (1, 1), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"1.\", \"gap_string\": 10},\n",
    "            {\"name\": \"phan1_3\", \"section_index\": (1, 2), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"1.\", \"gap_string\": 20},\n",
    "            {\"name\": \"phan1_4\", \"section_index\": (1, 3), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"1.\", \"gap_string\": 30},\n",
    "            {\"name\": \"phan2_1\", \"section_index\": (2, 0), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.1\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_2\", \"section_index\": (2, 1), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.2\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_3\", \"section_index\": (2, 2), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.3\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_4\", \"section_index\": (2, 3), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.4\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_5\", \"section_index\": (2, 4), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.5\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_6\", \"section_index\": (2, 5), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.6\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_7\", \"section_index\": (2, 6), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.7\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan2_8\", \"section_index\": (2, 7), \"axis\": 1, \"eps\": 0.002, \"input_string\": \"2.8\", \"gap_string\": \"a\"},\n",
    "            {\"name\": \"phan3_1\", \"section_index\": (3, 0), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"3.1\", \"gap_string\": \"none\"},\n",
    "            {\"name\": \"phan3_2\", \"section_index\": (3, 1), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"3.2\", \"gap_string\": \"none\"},\n",
    "            {\"name\": \"phan3_3\", \"section_index\": (3, 2), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"3.3\", \"gap_string\": \"none\"},\n",
    "            {\"name\": \"phan3_4\", \"section_index\": (3, 3), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"3.4\", \"gap_string\": \"none\"},\n",
    "            {\"name\": \"phan3_5\", \"section_index\": (3, 4), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"3.5\", \"gap_string\": \"none\"},\n",
    "            {\"name\": \"phan3_6\", \"section_index\": (3, 5), \"axis\": 0, \"eps\": 0.002, \"input_string\": \"3.6\", \"gap_string\": \"none\"}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers of black squares (YOLOv8 format): [(0.9157427937915743, 0.928911456680419), (0.7707317073170732, 0.9247857822913361), (0.6283813747228382, 0.9216121866074262), (0.4878048780487805, 0.9190733100602984), (0.34767184035476717, 0.9174865122183434), (0.20709534368070953, 0.9165344335131704), (0.06607538802660753, 0.9152649952396065), (0.9152993348115299, 0.6708981275785465), (0.7725055432372505, 0.6686766105998095), (0.7015521064301552, 0.6677245318946367), (0.6310421286031042, 0.6667724531894637), (0.4909090909090909, 0.6651856553475087), (0.3507760532150776, 0.6642335766423357), (0.2811529933481153, 0.6635988575055538), (0.2106430155210643, 0.6632814979371628), (0.06873614190687362, 0.6620120596635989), (0.9170731707317074, 0.5445890193589337), (0.7033259423503326, 0.5420501428118057), (0.49223946784922396, 0.5401459854014599), (0.282039911308204, 0.5385591875595049), (0.06962305986696231, 0.536337670580768), (0.9206208425720621, 0.34306569343065696), (0.8310421286031042, 0.3268803554427166), (0.6864745011086475, 0.3252935576007617), (0.493569844789357, 0.34052681688352904), (0.282039911308204, 0.3386226594731831), (0.07184035476718403, 0.33767058076801015), (0.8337028824833703, 0.13075214217708664), (0.6886917960088692, 0.13011742304030466), (0.9254988913525499, 0.07489685814027293), (0.07272727272727272, 0.07267534116153603)]\n",
      "Centers of black squares (YOLOv8 format): [(0.9175166297117516, 0.9282767375436369), (0.7725055432372505, 0.924468422722945), (0.6297117516629712, 0.9212948270390352), (0.48957871396895786, 0.9190733100602984), (0.34944567627494455, 0.9178038717867344), (0.20842572062084258, 0.9168517930815614), (0.06784922394678493, 0.9158997143763884), (0.9157427937915743, 0.6702634084417646), (0.7733924611973393, 0.6683592510314186), (0.7019955654101996, 0.6674071723262457), (0.6314855875831485, 0.6664550936210727), (0.49135254988913524, 0.6651856553475087), (0.35121951219512193, 0.6645509362107268), (0.28159645232815966, 0.6639162170739448), (0.21108647450110865, 0.6635988575055538), (0.06917960088691796, 0.6626467788003808), (0.9175166297117516, 0.5436369406537607), (0.7033259423503326, 0.5417327832434148), (0.49223946784922396, 0.5401459854014599), (0.282039911308204, 0.5388765471278959), (0.07006651884700665, 0.53697238971755), (0.9201773835920177, 0.34211361472548396), (0.8301552106430156, 0.3262456363059346), (0.6855875831485587, 0.32497619803237066), (0.4931263858093126, 0.34052681688352904), (0.28159645232815966, 0.3389400190415741), (0.07139689578713969, 0.33830529990479213), (0.8323725055432373, 0.13011742304030466), (0.6873614190687362, 0.12980006347191367), (0.9241685144124169, 0.07394477943509997), (0.07095343680709534, 0.07362741986670898)]\n",
      "Dữ liệu đã được ghi vào file test.txt.\n",
      "Processing SBD...\n",
      "Processing MDT...\n",
      "Processing phan1_1...\n",
      "Processing phan1_2...\n",
      "Processing phan1_3...\n",
      "Processing phan1_4...\n",
      "Processing phan2_1...\n",
      "Processing phan2_2...\n",
      "Processing phan2_3...\n",
      "Processing phan2_4...\n",
      "Processing phan2_5...\n",
      "Processing phan2_6...\n",
      "Processing phan2_7...\n",
      "Processing phan2_8...\n",
      "Processing phan3_1...\n",
      "Processing phan3_2...\n",
      "Processing phan3_3...\n",
      "Processing phan3_4...\n",
      "Processing phan3_5...\n",
      "Processing phan3_6...\n",
      "Centers of black squares (YOLOv8 format): [(0.9157427937915743, 0.928911456680419), (0.7707317073170732, 0.9247857822913361), (0.6283813747228382, 0.9216121866074262), (0.4878048780487805, 0.9190733100602984), (0.34767184035476717, 0.9174865122183434), (0.20709534368070953, 0.9165344335131704), (0.06607538802660753, 0.9152649952396065), (0.9152993348115299, 0.6708981275785465), (0.7725055432372505, 0.6686766105998095), (0.7015521064301552, 0.6677245318946367), (0.6310421286031042, 0.6667724531894637), (0.4909090909090909, 0.6651856553475087), (0.3507760532150776, 0.6642335766423357), (0.2811529933481153, 0.6635988575055538), (0.2106430155210643, 0.6632814979371628), (0.06873614190687362, 0.6620120596635989), (0.9170731707317074, 0.5445890193589337), (0.8869179600886918, 0.6480482386543954), (0.7033259423503326, 0.5420501428118057), (0.49223946784922396, 0.5401459854014599), (0.282039911308204, 0.5385591875595049), (0.9206208425720621, 0.34306569343065696), (0.8310421286031042, 0.3268803554427166), (0.493569844789357, 0.34052681688352904), (0.282039911308204, 0.3386226594731831), (0.07184035476718403, 0.33767058076801015), (0.06962305986696231, 0.536337670580768), (0.8337028824833703, 0.13075214217708664), (0.6864745011086475, 0.3252935576007617), (0.9254988913525499, 0.07489685814027293), (0.6886917960088692, 0.13011742304030466), (0.07272727272727272, 0.07267534116153603)]\n",
      "Centers of black squares (YOLOv8 format): [(0.9157427937915743, 0.928911456680419), (0.7707317073170732, 0.9247857822913361), (0.6283813747228382, 0.9216121866074262), (0.4878048780487805, 0.9190733100602984), (0.34767184035476717, 0.9174865122183434), (0.20709534368070953, 0.9165344335131704), (0.06607538802660753, 0.9152649952396065), (0.9152993348115299, 0.6708981275785465), (0.7725055432372505, 0.6686766105998095), (0.7015521064301552, 0.6677245318946367), (0.6310421286031042, 0.6667724531894637), (0.4909090909090909, 0.6651856553475087), (0.3507760532150776, 0.6642335766423357), (0.2811529933481153, 0.6635988575055538), (0.2106430155210643, 0.6632814979371628), (0.06873614190687362, 0.6620120596635989), (0.9170731707317074, 0.5445890193589337), (0.8869179600886918, 0.6480482386543954), (0.7033259423503326, 0.5420501428118057), (0.49223946784922396, 0.5401459854014599), (0.282039911308204, 0.5385591875595049), (0.9206208425720621, 0.34306569343065696), (0.8310421286031042, 0.3268803554427166), (0.493569844789357, 0.34052681688352904), (0.282039911308204, 0.3386226594731831), (0.07184035476718403, 0.33767058076801015), (0.06962305986696231, 0.536337670580768), (0.8337028824833703, 0.13075214217708664), (0.6864745011086475, 0.3252935576007617), (0.9254988913525499, 0.07489685814027293), (0.6886917960088692, 0.13011742304030466), (0.07272727272727272, 0.07267534116153603)]\n",
      "Dữ liệu đã được ghi vào file test.txt.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input must contain exactly 4 dots.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[699], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m fixed_circle(input_image_path, coord_saver)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m sections:\n\u001b[0;32m---> 15\u001b[0m     Bubbles \u001b[38;5;241m=\u001b[39m \u001b[43mgetBubblesInClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoord_saver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msection_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maxis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m Class \u001b[38;5;129;01min\u001b[39;00m Bubbles:\n\u001b[1;32m     17\u001b[0m             max_confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[692], line 6\u001b[0m, in \u001b[0;36mgetBubblesInClass\u001b[0;34m(input_image_path, input_data, section_index, axis, eps)\u001b[0m\n\u001b[1;32m      4\u001b[0m centers \u001b[38;5;241m=\u001b[39m image_processing\u001b[38;5;241m.\u001b[39mgetNails(input_image_path)\n\u001b[1;32m      5\u001b[0m gridmatrix \u001b[38;5;241m=\u001b[39m grid_info\u001b[38;5;241m.\u001b[39mgetGridmatrix(centers)\n\u001b[0;32m----> 6\u001b[0m gridsection \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetExtractsections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgridmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m dots \u001b[38;5;241m=\u001b[39m extract_bubbles(input_data)\n\u001b[1;32m      8\u001b[0m corners \u001b[38;5;241m=\u001b[39m gridsection[section_index[\u001b[38;5;241m0\u001b[39m]][section_index[\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[0;32m~/Desktop/AIChallenge/grid_info.py:127\u001b[0m, in \u001b[0;36mgetExtractsections\u001b[0;34m(matrix_dots)\u001b[0m\n\u001b[1;32m    125\u001b[0m dots_matrix[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(nearest_points[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    126\u001b[0m dots_matrix[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(nearest_points[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dotmatrix5 is \u001b[39m\u001b[38;5;124m\"\u001b[39m,dots_matrix[\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dots_matrix\n",
      "File \u001b[0;32m~/Desktop/AIChallenge/bubble_classify.py:15\u001b[0m, in \u001b[0;36msort_to_convex_quadrilateral\u001b[0;34m(dots)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msort_to_convex_quadrilateral\u001b[39m(dots):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Sorts a tuple of 4 dots into the order of a convex quadrilateral.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    :param dots: A tuple or list of 4 tuples, each representing (x, y) coordinates of a point\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    :return: A list of 4 tuples sorted into a convex quadrilateral order\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dots) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must contain exactly 4 dots.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Calculate the centroid of the points\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Input must contain exactly 4 dots."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "# Your existing loop where you get the output from the model\n",
    "folder_path = \"/Users/phamminhtuan/Desktop/Trainning_SET/Images\"\n",
    "coord_saver = \"test.txt\"\n",
    "result_txt_path = 'results_test_cnn.txt'\n",
    "for filename in os.listdir(folder_path):\n",
    "    with open(\"temp.txt\", 'w') as file:\n",
    "        pass\n",
    "    if filename.startswith(\"IMG_1581\"):\n",
    "        input_image_path = os.path.join(folder_path, filename)\n",
    "        input_image = cv2.imread(input_image_path)\n",
    "        fixed_circle(input_image_path, coord_saver)\n",
    "        for section in sections:\n",
    "            Bubbles = getBubblesInClass(input_image_path, coord_saver, section[\"section_index\"], axis=section[\"axis\"], eps=section[\"eps\"])\n",
    "            for Class in Bubbles:\n",
    "                    max_confidence = 0\n",
    "                    best_coords = None   \n",
    "                    for label in Class:\n",
    "                        _, x1, y1, x2, y2 = label\n",
    "                        coord = (x1, y1, x2, y2)\n",
    "                        x1, y1, x2, y2 = find_yolov8_square(image, coord)\n",
    "                        input = get_box(image, (x1, y1, x2, y2))\n",
    "                        \n",
    "                        transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Resize((32, 32))\n",
    "                        ])\n",
    "                        model.eval()\n",
    "                        input = transform(input).to(device)\n",
    "                        output = model(input.unsqueeze(0))\n",
    "                        confidence_score = output[0][0].item()  # Access the first element, which is the confidence score\n",
    "\n",
    "                        # Cập nhật bounding box có confidence cao nhất trong class\n",
    "                        if confidence_score > max_confidence:\n",
    "                            max_confidence = confidence_score\n",
    "                            best_coords = (x1, y1, x2, y2)\n",
    "\n",
    "                    if best_coords:\n",
    "                        x1, y1, x2, y2 = best_coords\n",
    "                        # Ghi tọa độ vào file txt\n",
    "                        cv2.rectangle(input_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        with open(\"temp.txt\", 'a') as f:     \n",
    "                            f.write(f\"0 {x1/w} {y1/h} {x2/w} {y2/h}\\n\")  # Ghi một dòng tọa độ\n",
    "        getSubmitResult(input_image_path, input_data, result_txt_path)\n",
    "cv2.imwrite(\"/Users/phamminhtuan/Desktop/AIChallenge/output1.jpg\", input_image)         \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SBD...\n",
      "Processing MDT...\n",
      "Processing phan1_1...\n",
      "Processing phan1_2...\n",
      "Processing phan1_3...\n",
      "Processing phan1_4...\n",
      "Processing phan2_1...\n",
      "Processing phan2_2...\n",
      "Processing phan2_3...\n",
      "Processing phan2_4...\n",
      "Processing phan2_5...\n",
      "Processing phan2_6...\n",
      "Processing phan2_7...\n",
      "Processing phan2_8...\n",
      "Processing phan3_1...\n",
      "Processing phan3_2...\n",
      "Processing phan3_3...\n",
      "Processing phan3_4...\n",
      "Processing phan3_5...\n",
      "Processing phan3_6...\n"
     ]
    }
   ],
   "source": [
    "from result_processsing import getSubmitResult\n",
    "input_image_path = '/Users/phamminhtuan/Desktop/Trainning_SET/Images/IMG_1581_iter_0.jpg'\n",
    "input_data = 'temp.txt'\n",
    "result_txt_path = 'results_test_cnn.txt'\n",
    "getSubmitResult(input_image_path, input_data, result_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the nails coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lens of the centers is:  31\n",
      "The smallest_and second smallest [(0.6886917960088692, 0.13011742304030466), (0.8337028824833703, 0.13075214217708664)]\n",
      "nearest point is [(0.8310421286031042, 0.3268803554427166), (0.6864745011086475, 0.3252935576007617)]\n",
      "The dotmatrix5 is  [(0.6886917960088692, 0.13011742304030466), (0.8337028824833703, 0.13075214217708664), (0.8310421286031042, 0.3268803554427166), (0.6864745011086475, 0.3252935576007617)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m center \u001b[38;5;129;01min\u001b[39;00m centers:\n\u001b[0;32m     14\u001b[0m     x1, y1 \u001b[38;5;241m=\u001b[39m center\n\u001b[1;32m---> 15\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x1\u001b[38;5;241m*\u001b[39m\u001b[43mw\u001b[49m)\n\u001b[0;32m     16\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(y1\u001b[38;5;241m*\u001b[39mh)\n\u001b[0;32m     17\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mcircle(input_image, (x1,y1),\u001b[38;5;241m10\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from utilities import extract_bubbles, append_to_file\n",
    "import image_processing \n",
    "import grid_info \n",
    "from fixed_coordinates import fixed_circle\n",
    "img_path = \"IMG_1581_iter_0.jpg\"\n",
    "input_image = cv2.imread(img_path)\n",
    "coord_saver = \"test.txt\"\n",
    "centers = image_processing.getNails(img_path)\n",
    "print(\"The lens of the centers is: \",len(centers))\n",
    "gridmatrix = grid_info.getGridmatrix(centers)\n",
    "gridsection = grid_info.getExtractsections(gridmatrix)\n",
    "for center in centers:\n",
    "    x1, y1 = center\n",
    "    x1 = int(x1*w)\n",
    "    y1 = int(y1*h)\n",
    "    cv2.circle(input_image, (x1,y1),10, (0, 255, 0), 2)\n",
    "cv2.imwrite(\"/Users/phamminhtuan/Desktop/AIChallenge/avg_coords.jpg\", input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(0.6886917960088692, 0.13011742304030466),\n",
       "   (0.8337028824833703, 0.13075214217708664),\n",
       "   (0.8310421286031042, 0.3268803554427166),\n",
       "   (0.6864745011086475, 0.3252935576007617)],\n",
       "  [(0.8337028824833703, 0.13075214217708664),\n",
       "   (0.9254988913525499, 0.07457949857188194),\n",
       "   (0.9206208425720621, 0.34306569343065696),\n",
       "   (0.8310421286031042, 0.3268803554427166)],\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " [[(0.07228381374722838, 0.33767058076801015),\n",
       "   (0.282039911308204, 0.3386226594731831),\n",
       "   (0.282039911308204, 0.5385591875595049),\n",
       "   (0.06962305986696231, 0.536337670580768)],\n",
       "  [(0.282039911308204, 0.3386226594731831),\n",
       "   (0.49401330376940134, 0.34052681688352904),\n",
       "   (0.49223946784922396, 0.5404633449698508),\n",
       "   (0.282039911308204, 0.5385591875595049)],\n",
       "  [(0.49401330376940134, 0.34052681688352904),\n",
       "   (0.7068736141906874, 0.34052681688352904),\n",
       "   (0.7033259423503326, 0.5420501428118057),\n",
       "   (0.49223946784922396, 0.5404633449698508)],\n",
       "  [(0.7068736141906874, 0.34052681688352904),\n",
       "   (0.9206208425720621, 0.34306569343065696),\n",
       "   (0.9170731707317074, 0.5445890193589337),\n",
       "   (0.7033259423503326, 0.5420501428118057)],\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " [[(0.06962305986696231, 0.536337670580768),\n",
       "   (0.18857649667405765, 0.5375817200888606),\n",
       "   (0.14820399113082042, 0.6624055855284037),\n",
       "   (0.06873614190687362, 0.6616947000952079)],\n",
       "  [(0.18857649667405765, 0.5375817200888606),\n",
       "   (0.282039911308204, 0.5385591875595049),\n",
       "   (0.2811529933481153, 0.6635988575055538),\n",
       "   (0.18768957871396896, 0.6627610282450016)],\n",
       "  [(0.282039911308204, 0.5385591875595049),\n",
       "   (0.3997516629711752, 0.5396255157092986),\n",
       "   (0.3986164079822616, 0.6644874642970485),\n",
       "   (0.2811529933481153, 0.6635988575055538)],\n",
       "  [(0.3997516629711752, 0.5396255157092986),\n",
       "   (0.49223946784922396, 0.5404633449698508),\n",
       "   (0.4909090909090909, 0.6651856553475087),\n",
       "   (0.3986164079822616, 0.6644874642970485)],\n",
       "  [(0.49223946784922396, 0.5404633449698508),\n",
       "   (0.6104478935698449, 0.5413519517613455),\n",
       "   (0.6088691796008869, 0.6666074262139003),\n",
       "   (0.4909090909090909, 0.6651856553475087)],\n",
       "  [(0.6104478935698449, 0.5413519517613455),\n",
       "   (0.7033259423503326, 0.5420501428118057),\n",
       "   (0.7015521064301552, 0.6677245318946367),\n",
       "   (0.6088691796008869, 0.6666074262139003)],\n",
       "  [(0.7033259423503326, 0.5420501428118057),\n",
       "   (0.8230243902439025, 0.5434719136781974),\n",
       "   (0.8212505543237251, 0.6695017454776262),\n",
       "   (0.7015521064301552, 0.6677245318946367)],\n",
       "  [(0.8230243902439025, 0.5434719136781974),\n",
       "   (0.9170731707317074, 0.5445890193589337),\n",
       "   (0.9152993348115299, 0.6708981275785465),\n",
       "   (0.8212505543237251, 0.6695017454776262)]],\n",
       " [[(0.06873614190687362, 0.6616947000952079),\n",
       "   (0.2106430155210643, 0.6629641383687718),\n",
       "   (0.20709534368070953, 0.9162170739447795),\n",
       "   (0.06607538802660753, 0.9152649952396065)],\n",
       "  [(0.2106430155210643, 0.6629641383687718),\n",
       "   (0.3507760532150776, 0.6639162170739448),\n",
       "   (0.34767184035476717, 0.9174865122183434),\n",
       "   (0.20709534368070953, 0.9162170739447795)],\n",
       "  [(0.3507760532150776, 0.6639162170739448),\n",
       "   (0.4909090909090909, 0.6651856553475087),\n",
       "   (0.4878048780487805, 0.9190733100602984),\n",
       "   (0.34767184035476717, 0.9174865122183434)],\n",
       "  [(0.4909090909090909, 0.6651856553475087),\n",
       "   (0.6310421286031042, 0.6667724531894637),\n",
       "   (0.6283813747228382, 0.9216121866074262),\n",
       "   (0.4878048780487805, 0.9190733100602984)],\n",
       "  [(0.6310421286031042, 0.6667724531894637),\n",
       "   (0.7725055432372505, 0.6686766105998095),\n",
       "   (0.7707317073170732, 0.9247857822913361),\n",
       "   (0.6283813747228382, 0.9216121866074262)],\n",
       "  [(0.7725055432372505, 0.6686766105998095),\n",
       "   (0.9152993348115299, 0.6708981275785465),\n",
       "   (0.9157427937915743, 0.928911456680419),\n",
       "   (0.7707317073170732, 0.9247857822913361)],\n",
       "  None,\n",
       "  None]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(folder_path):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(coord_saver, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(folder_path):\n",
    "    with open(coord_saver, 'w') as file:\n",
    "        pass\n",
    "    if filename.startswith(\"IMG_1581_iter_237\"):\n",
    "        input_image_path = os.path.join(folder_path, filename)\n",
    "        centers = image_processing.getNails(input_image_path)\n",
    "        for center in centers:\n",
    "            x1, y1 = center\n",
    "            x1 = int(x1*w)\n",
    "            y1 = int(y1*h)\n",
    "            cv2.circle(input_image, (x1,y1),10, (0, 255, 0), 2)\n",
    "        cv2.imwrite(\"/Users/phamminhtuan/Desktop/AIChallenge/avg_coords.jpg\", input_image)\n",
    "        print(input_image_path, len(centers))\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
