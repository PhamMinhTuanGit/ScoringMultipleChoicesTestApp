{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from train_utils import *\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Initializes the dataset by reading the image and label files, and processes them into tensors.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        label_path (str): Path to the label file (YOLO format).\n",
    "\n",
    "    The method reads the image from the specified path and the label data, then processes each labeled \n",
    "    bounding box to crop and transform the image into a tensor. The processed tensors and corresponding \n",
    "    labels are stored in `self.inputs` and `self.targets` respectively.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, label_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.inputs, self.targets = [], []\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((32, 32))\n",
    "        ])\n",
    "        image = cv2.imread(self.image_path)\n",
    "        labels, coords = read_file_to_tensors(self.label_path)\n",
    "        for i, coord in enumerate(coords):\n",
    "            square = find_yolov8_square(image, coord)\n",
    "            cropped_image = get_box(image, square)\n",
    "            cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "            cropped_tensor = self.transform(cropped_image)\n",
    "            self.inputs.append(cropped_tensor)\n",
    "            self.targets.append(labels[i])\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.inputs[idx]\n",
    "        label = self.targets[idx]\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_folder = \"/Users/phamminhtuan/Downloads/Trainning_SET/Images\"\n",
    "label_folder = \"/Users/phamminhtuan/Downloads/Trainning_SET/Labels\"\n",
    "train = []\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg') and 'iter_' in filename:\n",
    "        # Lấy số từ tên file\n",
    "        try:\n",
    "            number = int(filename.split('iter_')[1].split('.jpg')[0])\n",
    "            if 0 <= number <= 10:  # Kiểm tra nếu số nằm trong khoảng 0-10\n",
    "                # Lấy đường dẫn file ảnh và nhãn\n",
    "                image_path = os.path.join(image_folder, filename)\n",
    "                label_path = os.path.join(label_folder, os.path.splitext(filename)[0] + \".txt\")\n",
    "                # Tạo dataset tạm thời\n",
    "                temp = MyDataset(image_path, label_path)\n",
    "                # Thêm các phần tử từ dataset vào train\n",
    "                train.extend(temp[i] for i in range(len(temp)))\n",
    "        except ValueError:\n",
    "            # Bỏ qua file nếu không trích xuất được số hợp lệ\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115623"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_folder = \"/Users/phamminhtuan/Downloads/Trainning_SET/Images\"\n",
    "label_folder = \"/Users/phamminhtuan/Downloads/Trainning_SET/Labels\"\n",
    "test = []\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('iter_11.jpg'):  # Lọc các file hình ảnh\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        label_path = os.path.join(label_folder, os.path.splitext(filename)[0] + \".txt\")  # Giả định file nhãn cùng tên với file ảnh\n",
    "        temp_test = MyDataset(image_path,label_path)\n",
    "        for i in range(len(temp_test)):\n",
    "            test.append(temp_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904 89\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)\n",
    "print (len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the EfficientCNN model. This model is an efficient convolutional neural network for the \n",
    "        classification task. It consists of a feature extraction part and a classification part. The feature \n",
    "        extraction part is a convolutional neural network which consists of 3 convolutional layers with \n",
    "        maxpooling, where the number of channels are 32, 64, 128 respectively. The classification part is a \n",
    "        fully connected neural network which consists of 2 fully connected layers with dropout rate 0.5.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "        \"\"\"\n",
    "        super(EfficientCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientCNN().to(device)\n",
    "class MyDatasetPL(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyDatasetPL, self).__init__()\n",
    "        self.model = model\n",
    "        self.train_accuracies = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "\n",
    "    def accuracy(self, logits, labels):\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total = labels.size(0)\n",
    "        out = correct / total\n",
    "        return out\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return {'test_loss': loss, 'test_acc': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/amp.py:55: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | EfficientCNN | 618 K \n",
      "---------------------------------------\n",
      "618 K     Trainable params\n",
      "0         Non-trainable params\n",
      "618 K     Total params\n",
      "2.475     Total estimated model params size (MB)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb9cd0abfed441c8e8007b73d0e388b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad76634031c042a0a6c9b1f24179043b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 904: 'val_acc' reached 0.97008 (best 0.97008), saving model to '/Users/phamminhtuan/Desktop/AIChallenge/lightning_logs/version_4/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adba9534b7244cd8ff7fdc71e0e52f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1808: 'val_acc' reached 0.97087 (best 0.97087), saving model to '/Users/phamminhtuan/Desktop/AIChallenge/lightning_logs/version_4/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe580f8ae4934d8c919751b60088fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2712: 'val_acc' reached 0.97122 (best 0.97122), saving model to '/Users/phamminhtuan/Desktop/AIChallenge/lightning_logs/version_4/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffdaaf79dd04036b99af7db2b1a4c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3616: 'val_acc' reached 0.97140 (best 0.97140), saving model to '/Users/phamminhtuan/Desktop/AIChallenge/lightning_logs/version_4/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015cb5c1d44e41d49be9331f0cfb8a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 4520: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8e754f968941c9865a5f7a61bdf25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 5424: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59904aa19c1749b5bcce7f781ad592e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 6328: 'val_acc' was not in top 1\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    verbose=True\n",
    ")\n",
    "progress_bar = pl.callbacks.TQDMProgressBar()\n",
    "PARAMS = {\n",
    "    \"benchmark\": True,\n",
    "    \"enable_progress_bar\": True,\n",
    "    \"logger\": True,\n",
    "    \"callbacks\": [progress_bar, checkpoint_callback],\n",
    "    \"log_every_n_steps\": 1,\n",
    "    \"num_sanity_val_steps\": 0,\n",
    "    \"max_epochs\": 30,\n",
    "    \"precision\": 16\n",
    "}\n",
    "trainer = pl.Trainer(**PARAMS)\n",
    "Train = MyDatasetPL(num_classes=2)\n",
    "trainer.fit(Train, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MyDatasetPL.load_from_checkpoint(checkpoint_callback.best_model_path, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/Users/phamminhtuan/Desktop/Trainning_SET/Images/IMG_1587_iter_12.jpg\"\n",
    "label_path = \"/Users/phamminhtuan/Desktop/Trainning_SET/Labels/IMG_1587_iter_12.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_predicted_zero(file_path, label, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Ghi thông tin vào file khi predicted == 0.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Đường dẫn tới file cần ghi.\n",
    "        label (int): Nhãn dự đoán.\n",
    "        x1, y1, x2, y2 (int): Tọa độ của hình chữ nhật.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'a') as f:  # Mở file ở chế độ append\n",
    "        f.write(f\"{label} {x1} {y1} {x2} {y2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked_output_path = \"/Users/phamminhtuan/Desktop/AIChallenge/picked_output.txt\"\n",
    "image = cv2.imread(image_path)\n",
    "labels, coords = read_file_to_tensors(label_path)\n",
    "for i, coord in enumerate(coords):\n",
    "    xy_coord = find_yolov8_square(image, coord)\n",
    "    x1, y1, x2, y2 = xy_coord\n",
    "    input = get_box(image, xy_coord)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32))\n",
    "    ])\n",
    "    input = transform(input)\n",
    "    input = input.to(device)\n",
    "    output = model(input.unsqueeze(0))\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    if predicted == 0:\n",
    "        # Vẽ hình chữ nhật lên ảnh\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Ghi thông tin vào file picked_output.txt\n",
    "        a1, b1, a2, b2 = coord\n",
    "        handle_predicted_zero(picked_output_path, int(predicted.item()), a1, b1, a2, b2)\n",
    "\n",
    "cv2.imwrite(\"/Users/phamminhtuan/Desktop/AIChallenge/avg_coords.jpg\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
